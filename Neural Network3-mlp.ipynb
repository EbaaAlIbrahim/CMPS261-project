{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0630d47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ebaa\\AppData\\Local\\Temp\\ipykernel_13140\\1812555772.py:16: DtypeWarning: Columns (8,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('HIGGS_train.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class label</th>\n",
       "      <th>lepton pT</th>\n",
       "      <th>lepton eta</th>\n",
       "      <th>lepton phi</th>\n",
       "      <th>missing energy magnitude</th>\n",
       "      <th>missing energy phi</th>\n",
       "      <th>jet 1 pt</th>\n",
       "      <th>jet 1 eta</th>\n",
       "      <th>jet 1 phi</th>\n",
       "      <th>jet 1 b-tag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet 4 eta</th>\n",
       "      <th>jet 4 phi</th>\n",
       "      <th>jet 4 b-tag</th>\n",
       "      <th>m jj</th>\n",
       "      <th>m jjj</th>\n",
       "      <th>m lv</th>\n",
       "      <th>m jlv</th>\n",
       "      <th>m bb</th>\n",
       "      <th>m wbb</th>\n",
       "      <th>m wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.35900</td>\n",
       "      <td>1.500</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>1.100</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>-1.5900</td>\n",
       "      <td>2.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.140</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799</td>\n",
       "      <td>1.470</td>\n",
       "      <td>-1.64000</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.426</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.3800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.110</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.340</td>\n",
       "      <td>-0.877</td>\n",
       "      <td>0.93600</td>\n",
       "      <td>1.990</td>\n",
       "      <td>0.882</td>\n",
       "      <td>1.790</td>\n",
       "      <td>-1.650</td>\n",
       "      <td>-0.9420</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678</td>\n",
       "      <td>-1.360000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.110</td>\n",
       "      <td>0.321</td>\n",
       "      <td>1.52000</td>\n",
       "      <td>0.883</td>\n",
       "      <td>-1.210</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-0.9220</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>1.360</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.838</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.600</td>\n",
       "      <td>-0.608</td>\n",
       "      <td>0.00707</td>\n",
       "      <td>1.820</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.848</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>1.5800</td>\n",
       "      <td>2.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654</td>\n",
       "      <td>-1.270000</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599994</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.223</td>\n",
       "      <td>-0.75700</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>0.471</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.460</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.610</td>\n",
       "      <td>-1.620</td>\n",
       "      <td>0.21200</td>\n",
       "      <td>0.716</td>\n",
       "      <td>-0.906</td>\n",
       "      <td>0.553</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>-1.5600</td>\n",
       "      <td>2.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-0.490000</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.643</td>\n",
       "      <td>1.260</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.34400</td>\n",
       "      <td>0.617</td>\n",
       "      <td>-1.430</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.974</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.180</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-1.46000</td>\n",
       "      <td>0.735</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>1.020</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>1.2300</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.622000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812</td>\n",
       "      <td>1.240</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-1.02000</td>\n",
       "      <td>1.790</td>\n",
       "      <td>-1.650</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>2.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.340</td>\n",
       "      <td>0.510</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599995 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class label  lepton pT  lepton eta  lepton phi  \\\n",
       "0               1.0      0.908       0.329     0.35900   \n",
       "1               1.0      0.799       1.470    -1.64000   \n",
       "2               0.0      1.340      -0.877     0.93600   \n",
       "3               1.0      1.110       0.321     1.52000   \n",
       "4               0.0      1.600      -0.608     0.00707   \n",
       "...             ...        ...         ...         ...   \n",
       "599994          0.0      0.680       0.223    -0.75700   \n",
       "599995          1.0      1.610      -1.620     0.21200   \n",
       "599996          1.0      1.070       0.364     0.34400   \n",
       "599997          1.0      1.180      -0.173    -1.46000   \n",
       "599998          0.0      0.771      -0.133    -1.02000   \n",
       "\n",
       "        missing energy magnitude  missing energy phi  jet 1 pt  jet 1 eta  \\\n",
       "0                          1.500              -0.313     1.100     -0.558   \n",
       "1                          0.454               0.426     1.100      1.280   \n",
       "2                          1.990               0.882     1.790     -1.650   \n",
       "3                          0.883              -1.210     0.681     -1.070   \n",
       "4                          1.820              -0.112     0.848     -0.566   \n",
       "...                          ...                 ...       ...        ...   \n",
       "599994                     0.418              -0.323     0.471     -0.394   \n",
       "599995                     0.716              -0.906     0.553     -0.908   \n",
       "599996                     0.617              -1.430     0.675      0.159   \n",
       "599997                     0.735              -0.753     1.020     -0.838   \n",
       "599998                     1.790              -1.650     0.779      0.487   \n",
       "\n",
       "        jet 1 phi  jet 1 b-tag  ...  jet 4 eta  jet 4 phi  jet 4 b-tag   m jj  \\\n",
       "0         -1.5900         2.17  ...     -1.140  -0.000819          0.0  0.302   \n",
       "1          1.3800         0.00  ...      1.130   0.900000          0.0  0.910   \n",
       "2         -0.9420         0.00  ...     -0.678  -1.360000          0.0  0.947   \n",
       "3         -0.9220         0.00  ...     -0.374   0.113000          0.0  0.756   \n",
       "4          1.5800         2.17  ...     -0.654  -1.270000          3.1  0.824   \n",
       "...           ...          ...  ...        ...        ...          ...    ...   \n",
       "599994     0.1030         0.00  ...     -2.460   1.460000          0.0  0.823   \n",
       "599995    -1.5600         2.17  ...      0.538  -0.490000          3.1  0.810   \n",
       "599996     0.0789         0.00  ...      0.978   1.150000          3.1  0.973   \n",
       "599997     1.2300         0.00  ...      0.107   0.622000          0.0  0.812   \n",
       "599998     0.1900         2.17  ...     -0.314   0.667000          0.0  0.829   \n",
       "\n",
       "        m jjj   m lv  m jlv   m bb  m wbb  m wwbb  \n",
       "0       0.833  0.986  0.978  0.780  0.992   0.798  \n",
       "1       1.110  0.986  0.951  0.803  0.866   0.780  \n",
       "2       1.030  0.999  0.728  0.869  1.030   0.958  \n",
       "3       1.360  0.987  0.838  1.130  0.872   0.808  \n",
       "4       0.938  0.972  0.789  0.431  0.961   0.958  \n",
       "...       ...    ...    ...    ...    ...     ...  \n",
       "599994  1.040  0.985  0.868  0.258  0.776   0.712  \n",
       "599995  0.643  1.260  1.020  0.626  0.773   0.701  \n",
       "599996  0.974  1.130  0.969  0.852  0.908   0.789  \n",
       "599997  1.240  0.986  0.694  0.745  0.741   0.728  \n",
       "599998  0.839  0.984  1.340  0.510  1.040   0.905  \n",
       "\n",
       "[599995 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras import Sequential\n",
    "%matplotlib inline \n",
    "\n",
    "# read data from the Excel file\n",
    "data = pd.read_csv('HIGGS_train.csv')\n",
    "\n",
    "# Set the column names\n",
    "column_names = ['class label', 'lepton pT', 'lepton eta', 'lepton phi', 'missing energy magnitude', \n",
    "                'missing energy phi', 'jet 1 pt', 'jet 1 eta', 'jet 1 phi', 'jet 1 b-tag', \n",
    "                'jet 2 pt', 'jet 2 eta', 'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', \n",
    "                'jet 3 phi', 'jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', 'jet 4 phi', 'jet 4 b-tag', \n",
    "                'm jj', 'm jjj', 'm lv', 'm jlv', 'm bb', 'm wbb', 'm wwbb']\n",
    "\n",
    "data.columns = column_names\n",
    "\n",
    "# Split data into features and target\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    "\n",
    "data\n",
    "# i will now remove all the data that cannot be converted into floats so that we can start implementing:\n",
    "\n",
    "# convert the values in a column to numeric format\n",
    "for i in data.columns:\n",
    "\n",
    "  data[i] = pd.to_numeric(data[i], errors='coerce') # errors will convert non convertable data to NAN\n",
    "\n",
    "# drop rows with NaN values\n",
    "data.dropna(inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e539ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "model_1 =  MLPClassifier(hidden_layer_sizes=(300,50,55,45,30),activation='relu',solver='adam',alpha=.03,random_state = 7651)\n",
    "model_1.fit(X_train,y_train)\n",
    "model_1_predict=model_1.predict(X_test)\n",
    "model_1_predict_train=model_1.predict(X_train)\n",
    "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
    "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad09d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "15000/15000 [==============================] - 121s 8ms/step - loss: 0.6238 - accuracy: 0.6492\n",
      "Epoch 2/12\n",
      "15000/15000 [==============================] - 128s 9ms/step - loss: 0.5890 - accuracy: 0.6882\n",
      "Epoch 3/12\n",
      "15000/15000 [==============================] - 133s 9ms/step - loss: 0.5746 - accuracy: 0.7009\n",
      "Epoch 4/12\n",
      "15000/15000 [==============================] - 129s 9ms/step - loss: 0.5679 - accuracy: 0.7070\n",
      "Epoch 5/12\n",
      " 6506/15000 [============>.................] - ETA: 1:15 - loss: 0.5659 - accuracy: 0.7092"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=7651)\n",
    "model = Sequential([\n",
    "Dense(units=60, activation='relu'),\n",
    "Dense(units=50, activation='relu'),\n",
    "Dense(units=55, activation='relu'),\n",
    "Dense(units=40, activation='relu'),\n",
    "Dense(units=30, activation='relu'),\n",
    "Dense(units=1, activation='relu')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=12)\n",
    "model_predict=np.round(model.predict(X_test))\n",
    "model_predict_train=np.round(model.predict(X_train))\n",
    "print('training accuracy of model is:',accuracy_score(y_train,model_predict_train))\n",
    "print('testing accuracy of model is:',accuracy_score(y_test,model_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1267693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 10s 17ms/step - loss: 0.6726 - accuracy: 0.6042\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 0.6246 - accuracy: 0.6498\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 0.6176 - accuracy: 0.6592\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 9s 17ms/step - loss: 0.6040 - accuracy: 0.6691\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 0.5877 - accuracy: 0.6819\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 0.5668 - accuracy: 0.7026\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.5555 - accuracy: 0.7121\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.5517 - accuracy: 0.7169\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.5436 - accuracy: 0.7224\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.5354 - accuracy: 0.7285\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.5289 - accuracy: 0.7327\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.5244 - accuracy: 0.7367\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.5177 - accuracy: 0.7403\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.5169 - accuracy: 0.7414\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.5112 - accuracy: 0.7462\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.5146 - accuracy: 0.7451\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.5019 - accuracy: 0.7516\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.4954 - accuracy: 0.7552\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.4917 - accuracy: 0.7584\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.4873 - accuracy: 0.7608\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.5135 - accuracy: 0.7484\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.4980 - accuracy: 0.7544\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.5227 - accuracy: 0.7424\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.4863 - accuracy: 0.7626\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.4852 - accuracy: 0.7636\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.4843 - accuracy: 0.7645\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.4714 - accuracy: 0.7725\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.4823 - accuracy: 0.7660\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.4940 - accuracy: 0.7605\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.4808 - accuracy: 0.7683\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.5354 - accuracy: 0.7231\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.5040 - accuracy: 0.7527\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.4823 - accuracy: 0.7659\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.4683 - accuracy: 0.7749\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 10s 21ms/step - loss: 0.4693 - accuracy: 0.7750\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 10s 21ms/step - loss: 0.4674 - accuracy: 0.7757\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 10s 21ms/step - loss: 0.4772 - accuracy: 0.7692\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 10s 21ms/step - loss: 0.4535 - accuracy: 0.7843\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.4449 - accuracy: 0.7899\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.4800 - accuracy: 0.7691\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.4674 - accuracy: 0.7759\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.4493 - accuracy: 0.7874\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.4813 - accuracy: 0.7677\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.4563 - accuracy: 0.7832\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 9s 18ms/step - loss: 0.4444 - accuracy: 0.7903\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.4378 - accuracy: 0.7943\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 9s 19ms/step - loss: 0.4531 - accuracy: 0.7876\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.4390 - accuracy: 0.7952\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.4354 - accuracy: 0.7966\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 0.4196 - accuracy: 0.8046\n",
      "3750/3750 [==============================] - 7s 2ms/step\n",
      "15000/15000 [==============================] - 30s 2ms/step\n",
      "training accuracy of model is: 0.806231718597655\n",
      "testing accuracy of model is: 0.7214310119250994\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from keras import Sequential\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=7651)\n",
    "model = Sequential([\n",
    "Dense(units=300, activation='relu'),\n",
    "Dense(units=290, activation='relu'),\n",
    "Dense(units=280, activation='relu'),\n",
    "Dense(units=250, activation='relu'),\n",
    "Dense(units=200, activation='relu'),\n",
    "Dense(units=150, activation='relu'),\n",
    "Dense(units=100, activation='relu'),\n",
    "Dense(units=50, activation='relu'),\n",
    "Dense(units=1, activation='relu')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=50,steps_per_epoch=500)\n",
    "model_predict=np.round(model.predict(X_test))\n",
    "model_predict_train=np.round(model.predict(X_train))\n",
    "print('training accuracy of model is:',accuracy_score(y_train,model_predict_train))\n",
    "print('testing accuracy of model is:',accuracy_score(y_test,model_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5b0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
