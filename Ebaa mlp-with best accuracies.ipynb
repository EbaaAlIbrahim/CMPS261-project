{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gI5-6tdSataz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "%matplotlib inline \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "Zo2-5uCS9fm6",
        "outputId": "0f1fb545-4a8d-4c0c-973e-7777b1999c04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-193328a779fc>:2: DtypeWarning: Columns (8,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('HIGGS_train.csv')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-467580cc-e460-4aa0-8824-1871dc49e33d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class label</th>\n",
              "      <th>lepton pT</th>\n",
              "      <th>lepton eta</th>\n",
              "      <th>lepton phi</th>\n",
              "      <th>missing energy magnitude</th>\n",
              "      <th>missing energy phi</th>\n",
              "      <th>jet 1 pt</th>\n",
              "      <th>jet 1 eta</th>\n",
              "      <th>jet 1 phi</th>\n",
              "      <th>jet 1 b-tag</th>\n",
              "      <th>...</th>\n",
              "      <th>jet 4 eta</th>\n",
              "      <th>jet 4 phi</th>\n",
              "      <th>jet 4 b-tag</th>\n",
              "      <th>m jj</th>\n",
              "      <th>m jjj</th>\n",
              "      <th>m lv</th>\n",
              "      <th>m jlv</th>\n",
              "      <th>m bb</th>\n",
              "      <th>m wbb</th>\n",
              "      <th>m wwbb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.908</td>\n",
              "      <td>0.329</td>\n",
              "      <td>0.35900</td>\n",
              "      <td>1.500</td>\n",
              "      <td>-0.313</td>\n",
              "      <td>1.100</td>\n",
              "      <td>-0.558</td>\n",
              "      <td>-1.59</td>\n",
              "      <td>2.17</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.140</td>\n",
              "      <td>-0.000819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.302</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.992</td>\n",
              "      <td>0.798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.799</td>\n",
              "      <td>1.470</td>\n",
              "      <td>-1.64000</td>\n",
              "      <td>0.454</td>\n",
              "      <td>0.426</td>\n",
              "      <td>1.100</td>\n",
              "      <td>1.280</td>\n",
              "      <td>1.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.130</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.910</td>\n",
              "      <td>1.110</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.951</td>\n",
              "      <td>0.803</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.340</td>\n",
              "      <td>-0.877</td>\n",
              "      <td>0.93600</td>\n",
              "      <td>1.990</td>\n",
              "      <td>0.882</td>\n",
              "      <td>1.790</td>\n",
              "      <td>-1.650</td>\n",
              "      <td>-0.942</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.678</td>\n",
              "      <td>-1.360000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.947</td>\n",
              "      <td>1.030</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.728</td>\n",
              "      <td>0.869</td>\n",
              "      <td>1.030</td>\n",
              "      <td>0.958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.110</td>\n",
              "      <td>0.321</td>\n",
              "      <td>1.52000</td>\n",
              "      <td>0.883</td>\n",
              "      <td>-1.210</td>\n",
              "      <td>0.681</td>\n",
              "      <td>-1.070</td>\n",
              "      <td>-0.922</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>0.113000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.756</td>\n",
              "      <td>1.360</td>\n",
              "      <td>0.987</td>\n",
              "      <td>0.838</td>\n",
              "      <td>1.130</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.600</td>\n",
              "      <td>-0.608</td>\n",
              "      <td>0.00707</td>\n",
              "      <td>1.820</td>\n",
              "      <td>-0.112</td>\n",
              "      <td>0.848</td>\n",
              "      <td>-0.566</td>\n",
              "      <td>1.58</td>\n",
              "      <td>2.17</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.654</td>\n",
              "      <td>-1.270000</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.824</td>\n",
              "      <td>0.938</td>\n",
              "      <td>0.972</td>\n",
              "      <td>0.789</td>\n",
              "      <td>0.431</td>\n",
              "      <td>0.961</td>\n",
              "      <td>0.958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599994</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.223</td>\n",
              "      <td>-0.75700</td>\n",
              "      <td>0.418</td>\n",
              "      <td>-0.323</td>\n",
              "      <td>0.471</td>\n",
              "      <td>-0.394</td>\n",
              "      <td>0.103</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.460</td>\n",
              "      <td>1.460000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.823</td>\n",
              "      <td>1.040</td>\n",
              "      <td>0.985</td>\n",
              "      <td>0.868</td>\n",
              "      <td>0.258</td>\n",
              "      <td>0.776</td>\n",
              "      <td>0.712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599995</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.610</td>\n",
              "      <td>-1.620</td>\n",
              "      <td>0.21200</td>\n",
              "      <td>0.716</td>\n",
              "      <td>-0.906</td>\n",
              "      <td>0.553</td>\n",
              "      <td>-0.908</td>\n",
              "      <td>-1.56</td>\n",
              "      <td>2.17</td>\n",
              "      <td>...</td>\n",
              "      <td>0.538</td>\n",
              "      <td>-0.490000</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.810</td>\n",
              "      <td>0.643</td>\n",
              "      <td>1.260</td>\n",
              "      <td>1.020</td>\n",
              "      <td>0.626</td>\n",
              "      <td>0.773</td>\n",
              "      <td>0.701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599996</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.070</td>\n",
              "      <td>0.364</td>\n",
              "      <td>0.34400</td>\n",
              "      <td>0.617</td>\n",
              "      <td>-1.430</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.159</td>\n",
              "      <td>0.0789</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.978</td>\n",
              "      <td>1.150000</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.973</td>\n",
              "      <td>0.974</td>\n",
              "      <td>1.130</td>\n",
              "      <td>0.969</td>\n",
              "      <td>0.852</td>\n",
              "      <td>0.908</td>\n",
              "      <td>0.789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599997</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.180</td>\n",
              "      <td>-0.173</td>\n",
              "      <td>-1.46000</td>\n",
              "      <td>0.735</td>\n",
              "      <td>-0.753</td>\n",
              "      <td>1.020</td>\n",
              "      <td>-0.838</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.107</td>\n",
              "      <td>0.622000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.812</td>\n",
              "      <td>1.240</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.694</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.741</td>\n",
              "      <td>0.728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.771</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-1.02000</td>\n",
              "      <td>1.790</td>\n",
              "      <td>-1.650</td>\n",
              "      <td>0.779</td>\n",
              "      <td>0.487</td>\n",
              "      <td>0.19</td>\n",
              "      <td>2.17</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.314</td>\n",
              "      <td>0.667000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.839</td>\n",
              "      <td>0.984</td>\n",
              "      <td>1.340</td>\n",
              "      <td>0.510</td>\n",
              "      <td>1.040</td>\n",
              "      <td>0.905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>599999 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-467580cc-e460-4aa0-8824-1871dc49e33d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-467580cc-e460-4aa0-8824-1871dc49e33d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-467580cc-e460-4aa0-8824-1871dc49e33d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        class label  lepton pT  lepton eta  lepton phi  \\\n",
              "0               1.0      0.908       0.329     0.35900   \n",
              "1               1.0      0.799       1.470    -1.64000   \n",
              "2               0.0      1.340      -0.877     0.93600   \n",
              "3               1.0      1.110       0.321     1.52000   \n",
              "4               0.0      1.600      -0.608     0.00707   \n",
              "...             ...        ...         ...         ...   \n",
              "599994          0.0      0.680       0.223    -0.75700   \n",
              "599995          1.0      1.610      -1.620     0.21200   \n",
              "599996          1.0      1.070       0.364     0.34400   \n",
              "599997          1.0      1.180      -0.173    -1.46000   \n",
              "599998          0.0      0.771      -0.133    -1.02000   \n",
              "\n",
              "        missing energy magnitude  missing energy phi  jet 1 pt  jet 1 eta  \\\n",
              "0                          1.500              -0.313     1.100     -0.558   \n",
              "1                          0.454               0.426     1.100      1.280   \n",
              "2                          1.990               0.882     1.790     -1.650   \n",
              "3                          0.883              -1.210     0.681     -1.070   \n",
              "4                          1.820              -0.112     0.848     -0.566   \n",
              "...                          ...                 ...       ...        ...   \n",
              "599994                     0.418              -0.323     0.471     -0.394   \n",
              "599995                     0.716              -0.906     0.553     -0.908   \n",
              "599996                     0.617              -1.430     0.675      0.159   \n",
              "599997                     0.735              -0.753     1.020     -0.838   \n",
              "599998                     1.790              -1.650     0.779      0.487   \n",
              "\n",
              "       jet 1 phi  jet 1 b-tag  ...  jet 4 eta  jet 4 phi  jet 4 b-tag   m jj  \\\n",
              "0          -1.59         2.17  ...     -1.140  -0.000819          0.0  0.302   \n",
              "1           1.38         0.00  ...      1.130   0.900000          0.0  0.910   \n",
              "2         -0.942         0.00  ...     -0.678  -1.360000          0.0  0.947   \n",
              "3         -0.922         0.00  ...     -0.374   0.113000          0.0  0.756   \n",
              "4           1.58         2.17  ...     -0.654  -1.270000          3.1  0.824   \n",
              "...          ...          ...  ...        ...        ...          ...    ...   \n",
              "599994     0.103         0.00  ...     -2.460   1.460000          0.0  0.823   \n",
              "599995     -1.56         2.17  ...      0.538  -0.490000          3.1  0.810   \n",
              "599996    0.0789         0.00  ...      0.978   1.150000          3.1  0.973   \n",
              "599997      1.23         0.00  ...      0.107   0.622000          0.0  0.812   \n",
              "599998      0.19         2.17  ...     -0.314   0.667000          0.0  0.829   \n",
              "\n",
              "        m jjj   m lv  m jlv   m bb  m wbb  m wwbb  \n",
              "0       0.833  0.986  0.978  0.780  0.992   0.798  \n",
              "1       1.110  0.986  0.951  0.803  0.866   0.780  \n",
              "2       1.030  0.999  0.728  0.869  1.030   0.958  \n",
              "3       1.360  0.987  0.838  1.130  0.872   0.808  \n",
              "4       0.938  0.972  0.789  0.431  0.961   0.958  \n",
              "...       ...    ...    ...    ...    ...     ...  \n",
              "599994  1.040  0.985  0.868  0.258  0.776   0.712  \n",
              "599995  0.643  1.260  1.020  0.626  0.773   0.701  \n",
              "599996  0.974  1.130  0.969  0.852  0.908   0.789  \n",
              "599997  1.240  0.986  0.694  0.745  0.741   0.728  \n",
              "599998  0.839  0.984  1.340  0.510  1.040   0.905  \n",
              "\n",
              "[599999 rows x 29 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "# read data from the Excel file\n",
        "data = pd.read_csv('HIGGS_train.csv')\n",
        "\n",
        "# Set the column names\n",
        "column_names = ['class label', 'lepton pT', 'lepton eta', 'lepton phi', 'missing energy magnitude', \n",
        "                'missing energy phi', 'jet 1 pt', 'jet 1 eta', 'jet 1 phi', 'jet 1 b-tag', \n",
        "                'jet 2 pt', 'jet 2 eta', 'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', \n",
        "                'jet 3 phi', 'jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', 'jet 4 phi', 'jet 4 b-tag', \n",
        "                'm jj', 'm jjj', 'm lv', 'm jlv', 'm bb', 'm wbb', 'm wwbb']\n",
        "\n",
        "data.columns = column_names\n",
        "\n",
        "# Split data into features and target\n",
        "X = data.iloc[:, 1:].values\n",
        "y = data.iloc[:, 0].values\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZPjiQzqPjpZ",
        "outputId": "c81e75ef-a793-4d08-8abb-12bfb96c9736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> class label, Missing: 0 (0.0%)\n",
            "> lepton pT, Missing: 0 (0.0%)\n",
            "> lepton eta, Missing: 0 (0.0%)\n",
            "> lepton phi, Missing: 0 (0.0%)\n",
            "> missing energy magnitude, Missing: 0 (0.0%)\n",
            "> missing energy phi, Missing: 0 (0.0%)\n",
            "> jet 1 pt, Missing: 0 (0.0%)\n",
            "> jet 1 eta, Missing: 0 (0.0%)\n",
            "> jet 1 phi, Missing: 0 (0.0%)\n",
            "> jet 1 b-tag, Missing: 0 (0.0%)\n",
            "> jet 2 pt, Missing: 0 (0.0%)\n",
            "> jet 2 eta, Missing: 0 (0.0%)\n",
            "> jet 2 phi, Missing: 0 (0.0%)\n",
            "> jet 2 b-tag, Missing: 0 (0.0%)\n",
            "> jet 3 pt, Missing: 0 (0.0%)\n",
            "> jet 3 eta, Missing: 0 (0.0%)\n",
            "> jet 3 phi, Missing: 0 (0.0%)\n",
            "> jet 3 b-tag, Missing: 1 (0.0%)\n",
            "> jet 4 pt, Missing: 0 (0.0%)\n",
            "> jet 4 eta, Missing: 0 (0.0%)\n",
            "> jet 4 phi, Missing: 0 (0.0%)\n",
            "> jet 4 b-tag, Missing: 0 (0.0%)\n",
            "> m jj, Missing: 0 (0.0%)\n",
            "> m jjj, Missing: 0 (0.0%)\n",
            "> m lv, Missing: 0 (0.0%)\n",
            "> m jlv, Missing: 0 (0.0%)\n",
            "> m bb, Missing: 0 (0.0%)\n",
            "> m wbb, Missing: 0 (0.0%)\n",
            "> m wwbb, Missing: 0 (0.0%)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for col in data.columns:\n",
        "    n_miss = data[col].isnull().sum()\n",
        "    perc = n_miss / data.shape[0] * 100\n",
        "    print('> %s, Missing: %d (%.1f%%)' % (col, n_miss, perc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fvv968yThi-",
        "outputId": "08a31b84-34e8-4913-a91d-7b27835bc8e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> class label, Missing: 0 (0.0%)\n",
            "> lepton pT, Missing: 0 (0.0%)\n",
            "> lepton eta, Missing: 0 (0.0%)\n",
            "> lepton phi, Missing: 0 (0.0%)\n",
            "> missing energy magnitude, Missing: 0 (0.0%)\n",
            "> missing energy phi, Missing: 0 (0.0%)\n",
            "> jet 1 pt, Missing: 0 (0.0%)\n",
            "> jet 1 eta, Missing: 0 (0.0%)\n",
            "> jet 1 phi, Missing: 0 (0.0%)\n",
            "> jet 1 b-tag, Missing: 0 (0.0%)\n",
            "> jet 2 pt, Missing: 0 (0.0%)\n",
            "> jet 2 eta, Missing: 0 (0.0%)\n",
            "> jet 2 phi, Missing: 0 (0.0%)\n",
            "> jet 2 b-tag, Missing: 0 (0.0%)\n",
            "> jet 3 pt, Missing: 0 (0.0%)\n",
            "> jet 3 eta, Missing: 0 (0.0%)\n",
            "> jet 3 phi, Missing: 0 (0.0%)\n",
            "> jet 3 b-tag, Missing: 0 (0.0%)\n",
            "> jet 4 pt, Missing: 0 (0.0%)\n",
            "> jet 4 eta, Missing: 0 (0.0%)\n",
            "> jet 4 phi, Missing: 0 (0.0%)\n",
            "> jet 4 b-tag, Missing: 0 (0.0%)\n",
            "> m jj, Missing: 0 (0.0%)\n",
            "> m jjj, Missing: 0 (0.0%)\n",
            "> m lv, Missing: 0 (0.0%)\n",
            "> m jlv, Missing: 0 (0.0%)\n",
            "> m bb, Missing: 0 (0.0%)\n",
            "> m wbb, Missing: 0 (0.0%)\n",
            "> m wwbb, Missing: 0 (0.0%)\n"
          ]
        }
      ],
      "source": [
        "from numpy import NAN\n",
        "# remove NAs values:\n",
        "data=data.dropna()\n",
        "for col in data.columns:\n",
        "    n_miss = data[col].isnull().sum()\n",
        "    perc = n_miss / data.shape[0] * 100\n",
        "    print('> %s, Missing: %d (%.1f%%)' % (col, n_miss, perc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sznCNDh6Zq0w",
        "outputId": "26e552d5-de43-437d-87aa-e1cebb931ed4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-e0262c210070>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[i] = pd.to_numeric(data[i], errors='coerce') # errors will convert non convertable data to NAN\n",
            "<ipython-input-35-e0262c210070>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.dropna(inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# i will now remove all the data that cannot be converted into floats so that we can start implementing:\n",
        "\n",
        "# convert the values in a column to numeric format\n",
        "for i in data.columns:\n",
        "\n",
        "  data[i] = pd.to_numeric(data[i], errors='coerce') # errors will convert non convertable data to NAN\n",
        "\n",
        "# drop rows with NaN values\n",
        "data.dropna(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vYMXD4YLSSv",
        "outputId": "a04d375a-ff43-4e88-9926-92087b041918"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(599995, 29)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shape(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "bOpfEvRajH3N",
        "outputId": "233113d5-f206-4e17-d089-3eeadca514a8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-475e9e230731>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# MLPClassifier:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_1\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_1_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MLPClassifier' is not defined"
          ]
        }
      ],
      "source": [
        "# MLPClassifier:\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,1),activation='relu',solver='adam')\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "print('accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BEZSVGAsMIy"
      },
      "outputs": [],
      "source": [
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,55,345,30),activation='relu',solver='adam',alpha=0.01,random_state=7651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rH4eiug6L_6",
        "outputId": "88dc09db-3dc6-4b39-b37d-aae03e0bc18a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of model is: 0.62595\n"
          ]
        }
      ],
      "source": [
        "print('accuracy of model is:',accuracy_score(y_test[:20000],model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW_rLjBy6YM5"
      },
      "outputs": [],
      "source": [
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,40,30,1),activation='relu',solver='adam')\n",
        "model_1.fit(X_train[:40000],y_train[:40000])\n",
        "model_1_predict=model_1.predict(X_test[:40000])\n",
        "print('accuracy of model is:',accuracy_score(y_test[:40000],model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "ichBHWhd78uQ",
        "outputId": "5a5f05c8-694f-454e-d4ca-221ffc0f1e68"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-5f190d04ad27>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,55,45,,10),activation='relu',solver='adam',alpha=.01,random_state=9651)\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=9651)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,55,45,10),activation='relu',solver='adam',alpha=.01,random_state=9651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XC525k5zevSm"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('model_1.pkl', 'wb') as file:\n",
        "    pickle.dump(model_1, file)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC7UFEApAcZ0",
        "outputId": "eaa597bc-b510-48df-9fb7-abb040187592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7616934197937706\n",
            "testing accuracy of model is: 0.6932397959183674\n"
          ]
        }
      ],
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=1234)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,50,10,1),activation='relu',solver='adam',alpha=0.1,random_state=1234)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPNDBzojH1BL",
        "outputId": "0cbcb765-844a-4f5b-c776-a39c24fbbb33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7337301785803612\n",
            "testing accuracy of model is: 0.7316292331549197\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,5,1),activation='relu',solver='adam',alpha=.2)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "-jZUHLai7kWS",
        "outputId": "ab4d9289-d27f-4d44-9e71-792226d1e727"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-500aa5667edc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7651\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(400,300,200,150,100,50,55,45,30),activation='relu',batch_size=200000,solver='adam',alpha=.1,random_state = 7651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA6M_R-kKXV_"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_std = scaler.fit_transform(X_train)\n",
        "X_std_test = scaler.fit_transform(X_test)\n",
        "\n",
        "# Fit PCA\n",
        "pca = PCA(n_components=21)\n",
        "X_pca_train = pca.fit_transform(X_std)\n",
        "X_pca_test = pca.fit_transform(X_std_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Oew-uroa-9H"
      },
      "outputs": [],
      "source": [
        "model_1 =  MLPClassifier(hidden_layer_sizes=(1000,1000,750,1000),activation='relu',solver='adam',alpha=1.2,random_state = 7651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKYkzYhb2gH5",
        "outputId": "c4c0a03e-e162-4c46-9124-21fefbd14fc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7730793589946583\n",
            "testing accuracy of model is: 0.7538812823440195\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,55,45,30),activation='relu',solver='adam',alpha=.01,random_state = 7651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iPeBEchuys8",
        "outputId": "8757f3eb-c208-446c-c812-118fc1e57f4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.76604805040042\n",
            "testing accuracy of model is: 0.7539062825523546\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,55,45,30),activation='relu',solver='adam',alpha=.01,random_state = 7651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ6ha4YLt4A7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,55,45,30),activation='relu',solver='adam',alpha=.01,random_state = 7651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cGVyGciuvrW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,55,45,30,200),activation='relu',solver='adam',alpha=.03,random_state = 7651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikPyEngrupvW",
        "outputId": "cb9a7862-34ae-4659-d4ee-b8ec741918ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7674543121192676\n",
            "testing accuracy of model is: 0.7552812940107835\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,55,45,30),activation='relu',solver='adam',alpha=.03,random_state = 7651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "raUhkqm3DhJU",
        "outputId": "5fc07eaf-dcae-4db2-adf1-6c2186408ca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7728939407828399\n",
            "testing accuracy of model is: 0.7534146117884316\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(151,150,149,148,147,140),activation='relu',solver='adam',alpha=.03,random_state = 7651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0qMmxcqm3cP",
        "outputId": "30ff0818-708c-420f-f541-cc052652abb4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7557479645663714\n",
            "testing accuracy of model is: 0.7351977933149443\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(155,150,145,140),activation='relu',solver='adam',batch_size=100000,alpha=.1,random_state = 42)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1ku74VdyGYZ",
        "outputId": "8abbbf01-33c3-42e6-d10c-00784d031910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7558896324136034\n",
            "testing accuracy of model is: 0.7494645788714906\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 3)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(300,150,165,135,90),activation='relu',solver='adam',alpha=.1,random_state = 3)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj7Te5z6vHI0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 45)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(300,150,165,135,90),activation='relu',solver='adam',alpha=.1,random_state = 45)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7jtPyxNc2_T"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_std = scaler.fit_transform(X_train)\n",
        "X_std_test = scaler.fit_transform(X_test)\n",
        "\n",
        "# Fit PCA\n",
        "pca = PCA(n_components=21)\n",
        "X_pca_train = pca.fit_transform(X_std)\n",
        "X_pca_test = pca.fit_transform(X_std_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(500,250,275,225,150),activation='relu',batch_size=200000,solver='adam',alpha=.03,random_state = 7651)\n",
        "model_1.fit(X_pca_train,y_train)\n",
        "model_1_predict=model_1.predict(X_pca_test)\n",
        "model_1_predict_train=model_1.predict(X_pca_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFCA5VCZOSsX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7777)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,55,45,30),activation='relu',solver='adam',alpha=.03,random_state = 7777)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S25AquIm4-zF",
        "outputId": "de547d84-d33f-4735-f61b-aa1ae7be3b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7448726927117203\n",
            "testing accuracy of model is: 0.727852533640138\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,5,5),activation='relu',solver='adam',alpha=.2,random_state = 7651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLZINVBoBB13",
        "outputId": "835a6257-dba8-4e99-fdde-39765ad96112"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7574698778475659\n",
            "testing accuracy of model is: 0.714048028395541\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7777)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,5,10),activation='relu',solver='adam',alpha=.2,random_state = 7777)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfQDoaGUCw-l",
        "outputId": "95bd86ed-43b0-4cd3-e568-86753ad40187"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7960844668136378\n",
            "testing accuracy of model is: 0.6838223060285065\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 333)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,5,10),activation='relu',solver='adam',alpha=.001,random_state = 333)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m41AISdGuS-u",
        "outputId": "085e4895-32e0-4b08-ee56-10b82168cd1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7687105725881049\n",
            "testing accuracy of model is: 0.7518479320661006\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 45)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100000,50000,5000,10000),activation='relu',solver='adam',alpha=.001,random_state = 45)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9MflWlOJdBU"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 7651)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(450,400,300,200,100,50),activation='relu',solver='adam',batch_size=200000,alpha=1,random_state = 7651)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXCy2Az-gslb",
        "outputId": "b071c0a3-66dc-4103-c372-c1d2c69dd0ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7622855190459921\n",
            "testing accuracy of model is: 0.7506395886632389\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 45)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(50,55,45,40,30),activation='relu',solver='adam',alpha=.03,random_state = 45)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGZtXtB8iYlw"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 45)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(60,50,40,30,20,10),activation='relu',solver='adam',alpha=0.01,random_state = 45)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEd_4IvGxRw3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state = 45)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(40,35,30,25,20,10),activation='relu',solver='adam',alpha=0.01,random_state = 45)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBS1WBhzRBX-",
        "outputId": "2729289f-a2bc-4c24-c11b-bcfe80e23523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7427978566488054\n",
            "testing accuracy of model is: 0.741431178593155\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=6872187)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,1),activation='relu',solver='adam',alpha=.1,random_state=6872187)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwk6KMkyIoq4",
        "outputId": "15598f73-80dc-4139-88e7-f3f29d7c13e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.6733514445953717\n",
            "testing accuracy of model is: 0.6714972624771873\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=987218764)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,50,1),activation='relu',solver='adam',alpha=.1,random_state=987218764)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gc1TeOtDY9lb"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=42)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,40,100,40,1),activation='relu',solver='adam',alpha=.1,random_state=42)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FtnjdUdS9vX",
        "outputId": "7da9a9ca-1ff7-4252-aecd-d923ffda0c1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7920523700271949\n",
            "testing accuracy of model is: 0.7061262091202211\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=777)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,40,100,40,1),activation='relu',solver='adam',alpha=.01,random_state=777)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrIV22PZUUJy",
        "outputId": "9f224b72-16ea-4ae9-80c2-b5c35827c209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.9498382614242107\n",
            "testing accuracy of model is: 0.6213556851311953\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=1234)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,100,100,40,1),activation='relu',solver='adam',alpha=.001,random_state=1234)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLpVpKQhaPrg",
        "outputId": "e79df4bb-1b66-444d-a2bc-3900297bc896"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean cross-validation score: 0.5506388252677666\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(5,4,4,2,1),activation='relu',solver='adam',alpha=0.04)\n",
        "\n",
        "# Perform 5-fold cross-validation and calculate the mean accuracy score\n",
        "scores = cross_val_score(model_1, X_train, y_train, cv=5)\n",
        "mean_score = scores.mean()\n",
        "\n",
        "print(\"Mean cross-validation score:\", mean_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYPmdfVh45vm",
        "outputId": "0993742e-e252-4590-a679-75cf3058a3d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7140188619071484\n",
            "testing accuracy of model is: 0.6834912536443148\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=1234)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,70,50,20,40,1),activation='relu',solver='adam',alpha=1.2,random_state=1234)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5wES66IFDf5",
        "outputId": "32b82cd3-4f3c-4932-eb1f-efc944ee15c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7426306437650918\n",
            "testing accuracy of model is: 0.6904154518950437\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=1234)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,70,50,20,40,1),activation='relu',solver='adam',alpha=0.9,random_state=1234)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXWUHhBcKZNA",
        "outputId": "c1543c1c-f123-46f8-cd21-21694da9f854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7517426762039273\n",
            "testing accuracy of model is: 0.6860422740524781\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=77)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,70,50,20,40,1),activation='relu',solver='adam',alpha=0.8,random_state=77)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJCawwQnLouj",
        "outputId": "a74fb332-568b-46cc-f3a9-d0542933997a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training accuracy of model is: 0.7780308897899677\n",
            "testing accuracy of model is: 0.676567055393586\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=1234)\n",
        "\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(100,70,50,20,40,1),activation='relu',solver='adam',alpha=0.6,random_state=1234)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFY_B2T_SGXp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=3)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model_1 =  MLPClassifier(hidden_layer_sizes=(1000,700,500,200,400,100),activation='relu',solver='adam',alpha=1,random_state=3)\n",
        "model_1.fit(X_train,y_train)\n",
        "model_1_predict=model_1.predict(X_test)\n",
        "model_1_predict_train=model_1.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_1_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_1_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KZDLvZNmyj7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(100),Dense(100),Dense(100),Dense(100),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=10)\n",
        "model_predict=model.predict(X_test)\n",
        "model_predict_train=model.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "REntWrHeBc-V",
        "outputId": "97d05498-878d-4624-d97e-276e54485460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(32, 28) dtype=float32>,). Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-101a953ae379>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer 'sequential_4' (type Sequential).\n    \n    Dimension value must be integer or None or have an __index__ method, got value 'TensorShape([32, 28])' with type '<class 'tensorflow.python.framework.tensor_shape.TensorShape'>'\n    \n    Call arguments received by layer 'sequential_4' (type Sequential):\n      • inputs=('tf.Tensor(shape=(32, 28), dtype=float32)',)\n      • training=True\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "# implementing neural networks:\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Define the neural network architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='relu')) #change to sigmoid\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGaUOtHAmX7u"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(784,), activation='relu'),\n",
        "    Dense(32),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWBYMTiWdYuU",
        "outputId": "30d42190-2e92-46b0-fbc7-87788c1d1db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1054/1054 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[nan],\n",
              "       [nan],\n",
              "       [nan],\n",
              "       ...,\n",
              "       [nan],\n",
              "       [nan],\n",
              "       [nan]], dtype=float32)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_predicted=model.predict(X_test)\n",
        "print('accuracy of model is:',accuracy_score(y_test,y_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8wlakjNguQg",
        "outputId": "fbd52833-ea99-4cf2-d0ab-274146f7499b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[nan],\n",
              "       [nan],\n",
              "       [nan],\n",
              "       ...,\n",
              "       [nan],\n",
              "       [nan],\n",
              "       [nan]], dtype=float32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(y_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "ff-Fx8_XBY83",
        "outputId": "421eb7b8-00ec-4a5c-8321-9092b4e3cc0e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-901a8800b91c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define the neural network architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Define the neural network architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(70, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=12, batch_size=32, validation_split=0.3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRaksKuQ5DhP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from keras import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4kPyIetgNG6"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqnz_GAgg7rf"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(units=100, activation='relu'),\n",
        "    keras.layers.Dense(units=50, activation='relu'),\n",
        "    keras.layers.Dense(units=55, activation='relu'),\n",
        "    keras.layers.Dense(units=45, activation='relu'),\n",
        "    keras.layers.Dense(units=30, activation='relu')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPdUxE1Oh7kF"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "xEXPl9CTidUQ",
        "outputId": "044a71bd-c051-418a-a21d-5ff3e486e0fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "15000/15000 [==============================] - 40s 3ms/step - loss: 0.5456 - accuracy: 0.0431\n",
            "Epoch 2/12\n",
            "15000/15000 [==============================] - 39s 3ms/step - loss: 0.5409 - accuracy: 0.0180\n",
            "Epoch 3/12\n",
            "15000/15000 [==============================] - 40s 3ms/step - loss: 0.5371 - accuracy: 0.0485\n",
            "Epoch 4/12\n",
            "15000/15000 [==============================] - 39s 3ms/step - loss: 0.5416 - accuracy: 0.0292\n",
            "Epoch 5/12\n",
            "15000/15000 [==============================] - 38s 3ms/step - loss: 0.5487 - accuracy: 0.0559\n",
            "Epoch 6/12\n",
            "15000/15000 [==============================] - 37s 2ms/step - loss: 0.5488 - accuracy: 0.0160\n",
            "Epoch 7/12\n",
            "15000/15000 [==============================] - 38s 3ms/step - loss: 0.5579 - accuracy: 0.0184\n",
            "Epoch 8/12\n",
            "15000/15000 [==============================] - 38s 3ms/step - loss: 0.5437 - accuracy: 0.0434\n",
            "Epoch 9/12\n",
            "15000/15000 [==============================] - 41s 3ms/step - loss: 0.5394 - accuracy: 0.0854\n",
            "Epoch 10/12\n",
            "15000/15000 [==============================] - 42s 3ms/step - loss: 0.5443 - accuracy: 0.0492\n",
            "Epoch 11/12\n",
            "15000/15000 [==============================] - 42s 3ms/step - loss: 0.5394 - accuracy: 0.0667\n",
            "Epoch 12/12\n",
            "15000/15000 [==============================] - 39s 3ms/step - loss: 0.5662 - accuracy: 0.0340\n",
            "3750/3750 [==============================] - 6s 2ms/step\n",
            "15000/15000 [==============================] - 21s 1ms/step\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-cc32c11b748e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_predict_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training accuracy of model is:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_predict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testing accuracy of model is:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
          ]
        }
      ],
      "source": [
        "model.fit(X_train,y_train, epochs=12)\n",
        "model_predict=model.predict(X_test)\n",
        "model_predict_train=model.predict(X_train)\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "necDc9dP0H_V",
        "outputId": "065d793a-92be-4e44-f161-619d3a06b348"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-ff1c148d88d9>:16: DtypeWarning: Columns (8,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('HIGGS_train.csv')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5251906f-9383-467d-ab7f-ba1d374578df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class label</th>\n",
              "      <th>lepton pT</th>\n",
              "      <th>lepton eta</th>\n",
              "      <th>lepton phi</th>\n",
              "      <th>missing energy magnitude</th>\n",
              "      <th>missing energy phi</th>\n",
              "      <th>jet 1 pt</th>\n",
              "      <th>jet 1 eta</th>\n",
              "      <th>jet 1 phi</th>\n",
              "      <th>jet 1 b-tag</th>\n",
              "      <th>...</th>\n",
              "      <th>jet 4 eta</th>\n",
              "      <th>jet 4 phi</th>\n",
              "      <th>jet 4 b-tag</th>\n",
              "      <th>m jj</th>\n",
              "      <th>m jjj</th>\n",
              "      <th>m lv</th>\n",
              "      <th>m jlv</th>\n",
              "      <th>m bb</th>\n",
              "      <th>m wbb</th>\n",
              "      <th>m wwbb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.908</td>\n",
              "      <td>0.329</td>\n",
              "      <td>0.35900</td>\n",
              "      <td>1.500</td>\n",
              "      <td>-0.313</td>\n",
              "      <td>1.100</td>\n",
              "      <td>-0.558</td>\n",
              "      <td>-1.5900</td>\n",
              "      <td>2.17</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.140</td>\n",
              "      <td>-0.000819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.302</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.992</td>\n",
              "      <td>0.798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.799</td>\n",
              "      <td>1.470</td>\n",
              "      <td>-1.64000</td>\n",
              "      <td>0.454</td>\n",
              "      <td>0.426</td>\n",
              "      <td>1.100</td>\n",
              "      <td>1.280</td>\n",
              "      <td>1.3800</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.130</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.910</td>\n",
              "      <td>1.110</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.951</td>\n",
              "      <td>0.803</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.340</td>\n",
              "      <td>-0.877</td>\n",
              "      <td>0.93600</td>\n",
              "      <td>1.990</td>\n",
              "      <td>0.882</td>\n",
              "      <td>1.790</td>\n",
              "      <td>-1.650</td>\n",
              "      <td>-0.9420</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.678</td>\n",
              "      <td>-1.360000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.947</td>\n",
              "      <td>1.030</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.728</td>\n",
              "      <td>0.869</td>\n",
              "      <td>1.030</td>\n",
              "      <td>0.958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.110</td>\n",
              "      <td>0.321</td>\n",
              "      <td>1.52000</td>\n",
              "      <td>0.883</td>\n",
              "      <td>-1.210</td>\n",
              "      <td>0.681</td>\n",
              "      <td>-1.070</td>\n",
              "      <td>-0.9220</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>0.113000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.756</td>\n",
              "      <td>1.360</td>\n",
              "      <td>0.987</td>\n",
              "      <td>0.838</td>\n",
              "      <td>1.130</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.600</td>\n",
              "      <td>-0.608</td>\n",
              "      <td>0.00707</td>\n",
              "      <td>1.820</td>\n",
              "      <td>-0.112</td>\n",
              "      <td>0.848</td>\n",
              "      <td>-0.566</td>\n",
              "      <td>1.5800</td>\n",
              "      <td>2.17</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.654</td>\n",
              "      <td>-1.270000</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.824</td>\n",
              "      <td>0.938</td>\n",
              "      <td>0.972</td>\n",
              "      <td>0.789</td>\n",
              "      <td>0.431</td>\n",
              "      <td>0.961</td>\n",
              "      <td>0.958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599994</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.223</td>\n",
              "      <td>-0.75700</td>\n",
              "      <td>0.418</td>\n",
              "      <td>-0.323</td>\n",
              "      <td>0.471</td>\n",
              "      <td>-0.394</td>\n",
              "      <td>0.1030</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.460</td>\n",
              "      <td>1.460000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.823</td>\n",
              "      <td>1.040</td>\n",
              "      <td>0.985</td>\n",
              "      <td>0.868</td>\n",
              "      <td>0.258</td>\n",
              "      <td>0.776</td>\n",
              "      <td>0.712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599995</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.610</td>\n",
              "      <td>-1.620</td>\n",
              "      <td>0.21200</td>\n",
              "      <td>0.716</td>\n",
              "      <td>-0.906</td>\n",
              "      <td>0.553</td>\n",
              "      <td>-0.908</td>\n",
              "      <td>-1.5600</td>\n",
              "      <td>2.17</td>\n",
              "      <td>...</td>\n",
              "      <td>0.538</td>\n",
              "      <td>-0.490000</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.810</td>\n",
              "      <td>0.643</td>\n",
              "      <td>1.260</td>\n",
              "      <td>1.020</td>\n",
              "      <td>0.626</td>\n",
              "      <td>0.773</td>\n",
              "      <td>0.701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599996</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.070</td>\n",
              "      <td>0.364</td>\n",
              "      <td>0.34400</td>\n",
              "      <td>0.617</td>\n",
              "      <td>-1.430</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.159</td>\n",
              "      <td>0.0789</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.978</td>\n",
              "      <td>1.150000</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.973</td>\n",
              "      <td>0.974</td>\n",
              "      <td>1.130</td>\n",
              "      <td>0.969</td>\n",
              "      <td>0.852</td>\n",
              "      <td>0.908</td>\n",
              "      <td>0.789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599997</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.180</td>\n",
              "      <td>-0.173</td>\n",
              "      <td>-1.46000</td>\n",
              "      <td>0.735</td>\n",
              "      <td>-0.753</td>\n",
              "      <td>1.020</td>\n",
              "      <td>-0.838</td>\n",
              "      <td>1.2300</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.107</td>\n",
              "      <td>0.622000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.812</td>\n",
              "      <td>1.240</td>\n",
              "      <td>0.986</td>\n",
              "      <td>0.694</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.741</td>\n",
              "      <td>0.728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.771</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-1.02000</td>\n",
              "      <td>1.790</td>\n",
              "      <td>-1.650</td>\n",
              "      <td>0.779</td>\n",
              "      <td>0.487</td>\n",
              "      <td>0.1900</td>\n",
              "      <td>2.17</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.314</td>\n",
              "      <td>0.667000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.839</td>\n",
              "      <td>0.984</td>\n",
              "      <td>1.340</td>\n",
              "      <td>0.510</td>\n",
              "      <td>1.040</td>\n",
              "      <td>0.905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>599995 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5251906f-9383-467d-ab7f-ba1d374578df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5251906f-9383-467d-ab7f-ba1d374578df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5251906f-9383-467d-ab7f-ba1d374578df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        class label  lepton pT  lepton eta  lepton phi  \\\n",
              "0               1.0      0.908       0.329     0.35900   \n",
              "1               1.0      0.799       1.470    -1.64000   \n",
              "2               0.0      1.340      -0.877     0.93600   \n",
              "3               1.0      1.110       0.321     1.52000   \n",
              "4               0.0      1.600      -0.608     0.00707   \n",
              "...             ...        ...         ...         ...   \n",
              "599994          0.0      0.680       0.223    -0.75700   \n",
              "599995          1.0      1.610      -1.620     0.21200   \n",
              "599996          1.0      1.070       0.364     0.34400   \n",
              "599997          1.0      1.180      -0.173    -1.46000   \n",
              "599998          0.0      0.771      -0.133    -1.02000   \n",
              "\n",
              "        missing energy magnitude  missing energy phi  jet 1 pt  jet 1 eta  \\\n",
              "0                          1.500              -0.313     1.100     -0.558   \n",
              "1                          0.454               0.426     1.100      1.280   \n",
              "2                          1.990               0.882     1.790     -1.650   \n",
              "3                          0.883              -1.210     0.681     -1.070   \n",
              "4                          1.820              -0.112     0.848     -0.566   \n",
              "...                          ...                 ...       ...        ...   \n",
              "599994                     0.418              -0.323     0.471     -0.394   \n",
              "599995                     0.716              -0.906     0.553     -0.908   \n",
              "599996                     0.617              -1.430     0.675      0.159   \n",
              "599997                     0.735              -0.753     1.020     -0.838   \n",
              "599998                     1.790              -1.650     0.779      0.487   \n",
              "\n",
              "        jet 1 phi  jet 1 b-tag  ...  jet 4 eta  jet 4 phi  jet 4 b-tag   m jj  \\\n",
              "0         -1.5900         2.17  ...     -1.140  -0.000819          0.0  0.302   \n",
              "1          1.3800         0.00  ...      1.130   0.900000          0.0  0.910   \n",
              "2         -0.9420         0.00  ...     -0.678  -1.360000          0.0  0.947   \n",
              "3         -0.9220         0.00  ...     -0.374   0.113000          0.0  0.756   \n",
              "4          1.5800         2.17  ...     -0.654  -1.270000          3.1  0.824   \n",
              "...           ...          ...  ...        ...        ...          ...    ...   \n",
              "599994     0.1030         0.00  ...     -2.460   1.460000          0.0  0.823   \n",
              "599995    -1.5600         2.17  ...      0.538  -0.490000          3.1  0.810   \n",
              "599996     0.0789         0.00  ...      0.978   1.150000          3.1  0.973   \n",
              "599997     1.2300         0.00  ...      0.107   0.622000          0.0  0.812   \n",
              "599998     0.1900         2.17  ...     -0.314   0.667000          0.0  0.829   \n",
              "\n",
              "        m jjj   m lv  m jlv   m bb  m wbb  m wwbb  \n",
              "0       0.833  0.986  0.978  0.780  0.992   0.798  \n",
              "1       1.110  0.986  0.951  0.803  0.866   0.780  \n",
              "2       1.030  0.999  0.728  0.869  1.030   0.958  \n",
              "3       1.360  0.987  0.838  1.130  0.872   0.808  \n",
              "4       0.938  0.972  0.789  0.431  0.961   0.958  \n",
              "...       ...    ...    ...    ...    ...     ...  \n",
              "599994  1.040  0.985  0.868  0.258  0.776   0.712  \n",
              "599995  0.643  1.260  1.020  0.626  0.773   0.701  \n",
              "599996  0.974  1.130  0.969  0.852  0.908   0.789  \n",
              "599997  1.240  0.986  0.694  0.745  0.741   0.728  \n",
              "599998  0.839  0.984  1.340  0.510  1.040   0.905  \n",
              "\n",
              "[599995 rows x 29 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras import Sequential\n",
        "%matplotlib inline \n",
        "\n",
        "# read data from the Excel file\n",
        "data = pd.read_csv('HIGGS_train.csv')\n",
        "\n",
        "# Set the column names\n",
        "column_names = ['class label', 'lepton pT', 'lepton eta', 'lepton phi', 'missing energy magnitude', \n",
        "                'missing energy phi', 'jet 1 pt', 'jet 1 eta', 'jet 1 phi', 'jet 1 b-tag', \n",
        "                'jet 2 pt', 'jet 2 eta', 'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', \n",
        "                'jet 3 phi', 'jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', 'jet 4 phi', 'jet 4 b-tag', \n",
        "                'm jj', 'm jjj', 'm lv', 'm jlv', 'm bb', 'm wbb', 'm wwbb']\n",
        "\n",
        "data.columns = column_names\n",
        "\n",
        "# Split data into features and target\n",
        "X = data.iloc[:, 1:].values\n",
        "y = data.iloc[:, 0].values\n",
        "\n",
        "data\n",
        "# i will now remove all the data that cannot be converted into floats so that we can start implementing:\n",
        "\n",
        "# convert the values in a column to numeric format\n",
        "for i in data.columns:\n",
        "\n",
        "  data[i] = pd.to_numeric(data[i], errors='coerce') # errors will convert non convertable data to NAN\n",
        "\n",
        "# drop rows with NaN values\n",
        "data.dropna(inplace=True)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xygYps_M53Rf",
        "outputId": "de1132aa-4c59-49a3-a572-f97ed70a5f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "15000/15000 [==============================] - 35s 2ms/step - loss: 0.6282 - accuracy: 0.6483\n",
            "Epoch 2/12\n",
            "15000/15000 [==============================] - 23s 2ms/step - loss: 0.5936 - accuracy: 0.6833\n",
            "Epoch 3/12\n",
            "15000/15000 [==============================] - 26s 2ms/step - loss: 0.5818 - accuracy: 0.6950\n",
            "Epoch 4/12\n",
            "15000/15000 [==============================] - 24s 2ms/step - loss: 0.5708 - accuracy: 0.7040\n",
            "Epoch 5/12\n",
            "12851/15000 [========================>.....] - ETA: 3s - loss: 0.5651 - accuracy: 0.7081"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d3d81af1b499>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel_predict_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=7651)\n",
        "model = Sequential([\n",
        "Dense(units=55, activation='relu'),\n",
        "Dense(units=40, activation='relu'),\n",
        "Dense(units=30, activation='relu'),\n",
        "Dense(units=1, activation='relu')\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train,y_train, epochs=12)\n",
        "model_predict=np.round(model.predict(X_test))\n",
        "model_predict_train=np.round(model.predict(X_train))\n",
        "print('training accuracy of model is:',accuracy_score(y_train,model_predict_train))\n",
        "print('testing accuracy of model is:',accuracy_score(y_test,model_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jODVJG_76M4p",
        "outputId": "255b90bc-d359-472a-b507-146d6433d3c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-71360403d1b8>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "<ipython-input-7-71360403d1b8>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "<ipython-input-7-71360403d1b8>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "<ipython-input-7-71360403d1b8>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "<ipython-input-7-71360403d1b8>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "<ipython-input-7-71360403d1b8>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "<ipython-input-7-71360403d1b8>:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "<ipython-input-7-71360403d1b8>:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "<ipython-input-7-71360403d1b8>:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "<ipython-input-7-71360403d1b8>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "<ipython-input-7-71360403d1b8>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "<ipython-input-7-71360403d1b8>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "<ipython-input-7-71360403d1b8>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "<ipython-input-7-71360403d1b8>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Solver Penalty    C  Train Accuracy  Test Accuracy\n",
            "0   newton-cg      l2  0.1        0.635476       0.648214\n",
            "1   newton-cg      l2  1.0        0.639878       0.650000\n",
            "2   newton-cg      l2  3.0        0.640260       0.651786\n",
            "3   newton-cg    none  0.1        0.640452       0.650765\n",
            "4   newton-cg    none  1.0        0.640452       0.650765\n",
            "5   newton-cg    none  3.0        0.640452       0.650765\n",
            "6       lbfgs    none  0.1        0.640452       0.651276\n",
            "7       lbfgs    none  1.0        0.640452       0.651276\n",
            "8       lbfgs    none  3.0        0.640452       0.651276\n",
            "9   liblinear      l1  0.1        0.638411       0.648980\n",
            "10  liblinear      l1  1.0        0.640388       0.651276\n",
            "11  liblinear      l1  3.0        0.640515       0.650510\n",
            "12  liblinear      l2  0.1        0.635604       0.648214\n",
            "13  liblinear      l2  1.0        0.639814       0.650255\n",
            "14  liblinear      l2  3.0        0.640196       0.651786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-71360403d1b8>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:,0],test_size=0.2,random_state=7651)\n",
        "\n",
        "\n",
        "def build(solver,penalty, C ):\n",
        "  logreg = LogisticRegression(solver=solver,penalty=penalty, C=C )\n",
        "  logreg.fit(X_train, y_train)\n",
        "  y_pred = logreg.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  return (accuracy_score(y_train,logreg.predict(X_train)),accuracy)\n",
        "\n",
        "\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalties = ['l1', 'l2' , 'none']\n",
        "C_values = [0.1, 1.0, 3]\n",
        "\n",
        "\n",
        "results_table = pd.DataFrame(columns=['Solver', 'Penalty', 'C', 'Train Accuracy', 'Test Accuracy'])\n",
        "\n",
        "\n",
        "for solver in solvers:\n",
        "    for penalty in penalties:\n",
        "      if solver == solvers[0]:\n",
        "        if penalty in [penalties[1],penalties[-1]]:\n",
        "          for C in C_values:\n",
        "              train_acc, test_acc = build(solver=solver, penalty=penalty, C=C)\n",
        "              \n",
        "              results_table = results_table.append({\n",
        "                  'Solver': solver,\n",
        "                  'Penalty': penalty,\n",
        "                  'C': C,\n",
        "                  'Train Accuracy': train_acc,\n",
        "                  'Test Accuracy': test_acc\n",
        "              }, ignore_index=True)\n",
        "      elif solver==solvers[1]:\n",
        "        if penalty in [penalties[-1]]:\n",
        "          for C in C_values:\n",
        "              train_acc, test_acc = build(solver=solver, penalty=penalty, C=C)\n",
        "              results_table = results_table.append({\n",
        "                  'Solver': solver,\n",
        "                  'Penalty': penalty,\n",
        "                  'C': C,\n",
        "                  'Train Accuracy': train_acc,\n",
        "                  'Test Accuracy': test_acc\n",
        "              }, ignore_index=True)\n",
        "      elif solver == solvers[-1] and penalty != penalties[-1]:\n",
        "        for C in C_values:\n",
        "              train_acc, test_acc = build(solver=solver, penalty=penalty, C=C)\n",
        "              results_table = results_table.append({\n",
        "                  'Solver': solver,\n",
        "                  'Penalty': penalty,\n",
        "                  'C': C,\n",
        "                  'Train Accuracy': train_acc,\n",
        "                  'Test Accuracy': test_acc\n",
        "              }, ignore_index=True)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "print(results_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK6bMevJsh0K"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# Initialize SVM model\n",
        "svm_model = svm.SVC(kernel='linear',C=10)\n",
        "\n",
        "# Train SVM model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy of SVM model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy_score(svm_model.predict(X_train), y_train))\n",
        "print(accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}